{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GTZAN dataset\n",
    "general_path = 'Data'\n",
    "print(list(os.listdir(f'{general_path}/genres_original/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next Steps\n",
    "# Ensure all MEL-spectrograms are same NxN dimensions\n",
    "# Convert them into compressed vector representations\n",
    "# create train-test-split,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/features_3_sec.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Some logic derived from reading through the following Kaggle set: https://www.kaggle.com/code/aishwarya2210/let-s-tune-the-music-with-cnn-xgboost/notebook\n",
    "This is for scaling and extracting the features as needed, and converting the labels to numerical values. \n",
    "This will help to create the training and testing sets, then will be fed into the model\n",
    "'''\n",
    "\n",
    "# Label Encoding - encod the categorical classes with numerical integer values for training\n",
    "\n",
    "# Blues - 0\n",
    "# Classical - 1\n",
    "# Country - 2\n",
    "# Disco - 3\n",
    "# Hip-hop - 4 \n",
    "# Jazz - 5  \n",
    "# Metal - 6 \n",
    "# Pop - 7\n",
    "# Reggae - 8\n",
    "# Rock - 9\n",
    "\n",
    "#To convert categorical data into model-understandable numerica data\n",
    "class_list = df.iloc[:, -1]\n",
    "convertor = LabelEncoder()\n",
    "\n",
    "df = df.drop(labels=\"filename\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the label encoder & return encoded labels\n",
    "y = convertor.fit_transform(class_list)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fit = StandardScaler()\n",
    "X = fit.fit_transform(np.array(df.iloc[:, :-1], dtype = float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(df.iloc[:,:-1],y,test_size=0.3)\n",
    "x_train.head()\n",
    "# y_train.item(1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORING PREVIOUSLY MADE TRAIN/TEST SPLIT\n",
    "\n",
    "# Removing other unecessary variables\n",
    "df = df.drop(labels=\"length\", axis=1)\n",
    "df = df.drop(labels=\"label\", axis=1)\n",
    "\n",
    "# Creataing edge tensor, 1 - Identity Matrix --> tensor\n",
    "adj_matrix = 1 - torch.eye(df.shape[0])\n",
    "edge_index = torch.nonzero(adj_matrix, as_tuple=False).t()\n",
    "\n",
    "# Setting data features to tensor\n",
    "x = torch.tensor(df.values)\n",
    "x = x.to(torch.float32)\n",
    "\n",
    "# Setting y to tensor\n",
    "y = torch.tensor(y, dtype=torch.long)  # Make sure target is of type long (integer labels)\n",
    "\n",
    "# Create data object\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# Set train/test split\n",
    "train_mask = torch.rand(df.shape[0]) < 0.80  # 80% training nodes\n",
    "test_mask = ~train_mask                     # 20% testing nodes (the inverse of the train_mask)\n",
    "data.train_mask = train_mask\n",
    "data.test_mask = test_mask\n",
    "\n",
    "# Check dimmensions\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from https://www.geeksforgeeks.org/graph-neural-networks-with-pytorch/\n",
    "\n",
    "class CustomGNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(CustomGNN, self).__init__()\n",
    "        self.layer1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.layer2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, feature_data, edge_info):\n",
    "        # First GCN layer\n",
    "        x = self.layer1(feature_data, edge_info)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        # Second GCN layer\n",
    "        x = self.layer2(x, edge_info)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Initialize the GNN model\n",
    "input_features = df.shape[1]\n",
    "hidden_dim = df.shape[1] # PICK!\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "weight_decay=5e-4\n",
    "\n",
    "model = CustomGNN(input_features, hidden_dim, num_classes)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "graph_data = data  # Get the graph data\n",
    "\n",
    "def train_model():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(graph_data.x, graph_data.edge_index)\n",
    "    loss = F.nll_loss(output[graph_data.train_mask], graph_data.y[graph_data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "for epoch in range(200):\n",
    "    loss_value = train_model()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch+1:03d}, Loss: {loss_value:.4f}')\n",
    "\n",
    "def evaluate_model():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(graph_data.x, graph_data.edge_index).argmax(dim=1)\n",
    "        correct = (predictions[graph_data.test_mask] == graph_data.y[graph_data.test_mask]).sum()\n",
    "        acc = int(correct) / int(graph_data.test_mask.sum())\n",
    "    return acc\n",
    "\n",
    "accuracy = evaluate_model()\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
