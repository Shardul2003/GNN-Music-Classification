{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['country', 'metal', 'jazz', 'hiphop', 'blues', 'classical', 'reggae', 'rock', 'pop', 'disco']\n"
     ]
    }
   ],
   "source": [
    "# GTZAN dataset\n",
    "general_path = 'Data'\n",
    "print(list(os.listdir(f'{general_path}/genres_original/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next Steps\n",
    "# Ensure all MEL-spectrograms are same NxN dimensions\n",
    "# Convert them into compressed vector representations\n",
    "# create train-test-split,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.0.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.335406</td>\n",
       "      <td>0.091048</td>\n",
       "      <td>0.130405</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>1773.065032</td>\n",
       "      <td>167541.630869</td>\n",
       "      <td>1972.744388</td>\n",
       "      <td>117335.771563</td>\n",
       "      <td>...</td>\n",
       "      <td>39.687145</td>\n",
       "      <td>-3.241280</td>\n",
       "      <td>36.488243</td>\n",
       "      <td>0.722209</td>\n",
       "      <td>38.099152</td>\n",
       "      <td>-5.050335</td>\n",
       "      <td>33.618073</td>\n",
       "      <td>-0.243027</td>\n",
       "      <td>43.771767</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00000.1.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.343065</td>\n",
       "      <td>0.086147</td>\n",
       "      <td>0.112699</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>1816.693777</td>\n",
       "      <td>90525.690866</td>\n",
       "      <td>2010.051501</td>\n",
       "      <td>65671.875673</td>\n",
       "      <td>...</td>\n",
       "      <td>64.748276</td>\n",
       "      <td>-6.055294</td>\n",
       "      <td>40.677654</td>\n",
       "      <td>0.159015</td>\n",
       "      <td>51.264091</td>\n",
       "      <td>-2.837699</td>\n",
       "      <td>97.030830</td>\n",
       "      <td>5.784063</td>\n",
       "      <td>59.943081</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00000.2.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.346815</td>\n",
       "      <td>0.092243</td>\n",
       "      <td>0.132003</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>1788.539719</td>\n",
       "      <td>111407.437613</td>\n",
       "      <td>2084.565132</td>\n",
       "      <td>75124.921716</td>\n",
       "      <td>...</td>\n",
       "      <td>67.336563</td>\n",
       "      <td>-1.768610</td>\n",
       "      <td>28.348579</td>\n",
       "      <td>2.378768</td>\n",
       "      <td>45.717648</td>\n",
       "      <td>-1.938424</td>\n",
       "      <td>53.050835</td>\n",
       "      <td>2.517375</td>\n",
       "      <td>33.105122</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00000.3.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.363639</td>\n",
       "      <td>0.086856</td>\n",
       "      <td>0.132565</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>1655.289045</td>\n",
       "      <td>111952.284517</td>\n",
       "      <td>1960.039988</td>\n",
       "      <td>82913.639269</td>\n",
       "      <td>...</td>\n",
       "      <td>47.739452</td>\n",
       "      <td>-3.841155</td>\n",
       "      <td>28.337118</td>\n",
       "      <td>1.218588</td>\n",
       "      <td>34.770935</td>\n",
       "      <td>-3.580352</td>\n",
       "      <td>50.836224</td>\n",
       "      <td>3.630866</td>\n",
       "      <td>32.023678</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00000.4.wav</td>\n",
       "      <td>66149</td>\n",
       "      <td>0.335579</td>\n",
       "      <td>0.088129</td>\n",
       "      <td>0.143289</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>1630.656199</td>\n",
       "      <td>79667.267654</td>\n",
       "      <td>1948.503884</td>\n",
       "      <td>60204.020268</td>\n",
       "      <td>...</td>\n",
       "      <td>30.336359</td>\n",
       "      <td>0.664582</td>\n",
       "      <td>45.880913</td>\n",
       "      <td>1.689446</td>\n",
       "      <td>51.363583</td>\n",
       "      <td>-3.392489</td>\n",
       "      <td>26.738789</td>\n",
       "      <td>0.536961</td>\n",
       "      <td>29.146694</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
       "0  blues.00000.0.wav   66149          0.335406         0.091048  0.130405   \n",
       "1  blues.00000.1.wav   66149          0.343065         0.086147  0.112699   \n",
       "2  blues.00000.2.wav   66149          0.346815         0.092243  0.132003   \n",
       "3  blues.00000.3.wav   66149          0.363639         0.086856  0.132565   \n",
       "4  blues.00000.4.wav   66149          0.335579         0.088129  0.143289   \n",
       "\n",
       "    rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
       "0  0.003521             1773.065032          167541.630869   \n",
       "1  0.001450             1816.693777           90525.690866   \n",
       "2  0.004620             1788.539719          111407.437613   \n",
       "3  0.002448             1655.289045          111952.284517   \n",
       "4  0.001701             1630.656199           79667.267654   \n",
       "\n",
       "   spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
       "0              1972.744388           117335.771563  ...   39.687145   \n",
       "1              2010.051501            65671.875673  ...   64.748276   \n",
       "2              2084.565132            75124.921716  ...   67.336563   \n",
       "3              1960.039988            82913.639269  ...   47.739452   \n",
       "4              1948.503884            60204.020268  ...   30.336359   \n",
       "\n",
       "   mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \\\n",
       "0    -3.241280   36.488243     0.722209   38.099152    -5.050335   33.618073   \n",
       "1    -6.055294   40.677654     0.159015   51.264091    -2.837699   97.030830   \n",
       "2    -1.768610   28.348579     2.378768   45.717648    -1.938424   53.050835   \n",
       "3    -3.841155   28.337118     1.218588   34.770935    -3.580352   50.836224   \n",
       "4     0.664582   45.880913     1.689446   51.363583    -3.392489   26.738789   \n",
       "\n",
       "   mfcc20_mean  mfcc20_var  label  \n",
       "0    -0.243027   43.771767  blues  \n",
       "1     5.784063   59.943081  blues  \n",
       "2     2.517375   33.105122  blues  \n",
       "3     3.630866   32.023678  blues  \n",
       "4     0.536961   29.146694  blues  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data/features_3_sec.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9990, 60)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66149</td>\n",
       "      <td>0.335406</td>\n",
       "      <td>0.091048</td>\n",
       "      <td>0.130405</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>1773.065032</td>\n",
       "      <td>167541.630869</td>\n",
       "      <td>1972.744388</td>\n",
       "      <td>117335.771563</td>\n",
       "      <td>3714.560359</td>\n",
       "      <td>...</td>\n",
       "      <td>39.687145</td>\n",
       "      <td>-3.241280</td>\n",
       "      <td>36.488243</td>\n",
       "      <td>0.722209</td>\n",
       "      <td>38.099152</td>\n",
       "      <td>-5.050335</td>\n",
       "      <td>33.618073</td>\n",
       "      <td>-0.243027</td>\n",
       "      <td>43.771767</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66149</td>\n",
       "      <td>0.343065</td>\n",
       "      <td>0.086147</td>\n",
       "      <td>0.112699</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>1816.693777</td>\n",
       "      <td>90525.690866</td>\n",
       "      <td>2010.051501</td>\n",
       "      <td>65671.875673</td>\n",
       "      <td>3869.682242</td>\n",
       "      <td>...</td>\n",
       "      <td>64.748276</td>\n",
       "      <td>-6.055294</td>\n",
       "      <td>40.677654</td>\n",
       "      <td>0.159015</td>\n",
       "      <td>51.264091</td>\n",
       "      <td>-2.837699</td>\n",
       "      <td>97.030830</td>\n",
       "      <td>5.784063</td>\n",
       "      <td>59.943081</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66149</td>\n",
       "      <td>0.346815</td>\n",
       "      <td>0.092243</td>\n",
       "      <td>0.132003</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>1788.539719</td>\n",
       "      <td>111407.437613</td>\n",
       "      <td>2084.565132</td>\n",
       "      <td>75124.921716</td>\n",
       "      <td>3997.639160</td>\n",
       "      <td>...</td>\n",
       "      <td>67.336563</td>\n",
       "      <td>-1.768610</td>\n",
       "      <td>28.348579</td>\n",
       "      <td>2.378768</td>\n",
       "      <td>45.717648</td>\n",
       "      <td>-1.938424</td>\n",
       "      <td>53.050835</td>\n",
       "      <td>2.517375</td>\n",
       "      <td>33.105122</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66149</td>\n",
       "      <td>0.363639</td>\n",
       "      <td>0.086856</td>\n",
       "      <td>0.132565</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>1655.289045</td>\n",
       "      <td>111952.284517</td>\n",
       "      <td>1960.039988</td>\n",
       "      <td>82913.639269</td>\n",
       "      <td>3568.300218</td>\n",
       "      <td>...</td>\n",
       "      <td>47.739452</td>\n",
       "      <td>-3.841155</td>\n",
       "      <td>28.337118</td>\n",
       "      <td>1.218588</td>\n",
       "      <td>34.770935</td>\n",
       "      <td>-3.580352</td>\n",
       "      <td>50.836224</td>\n",
       "      <td>3.630866</td>\n",
       "      <td>32.023678</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66149</td>\n",
       "      <td>0.335579</td>\n",
       "      <td>0.088129</td>\n",
       "      <td>0.143289</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>1630.656199</td>\n",
       "      <td>79667.267654</td>\n",
       "      <td>1948.503884</td>\n",
       "      <td>60204.020268</td>\n",
       "      <td>3469.992864</td>\n",
       "      <td>...</td>\n",
       "      <td>30.336359</td>\n",
       "      <td>0.664582</td>\n",
       "      <td>45.880913</td>\n",
       "      <td>1.689446</td>\n",
       "      <td>51.363583</td>\n",
       "      <td>-3.392489</td>\n",
       "      <td>26.738789</td>\n",
       "      <td>0.536961</td>\n",
       "      <td>29.146694</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   length  chroma_stft_mean  chroma_stft_var  rms_mean   rms_var  \\\n",
       "0   66149          0.335406         0.091048  0.130405  0.003521   \n",
       "1   66149          0.343065         0.086147  0.112699  0.001450   \n",
       "2   66149          0.346815         0.092243  0.132003  0.004620   \n",
       "3   66149          0.363639         0.086856  0.132565  0.002448   \n",
       "4   66149          0.335579         0.088129  0.143289  0.001701   \n",
       "\n",
       "   spectral_centroid_mean  spectral_centroid_var  spectral_bandwidth_mean  \\\n",
       "0             1773.065032          167541.630869              1972.744388   \n",
       "1             1816.693777           90525.690866              2010.051501   \n",
       "2             1788.539719          111407.437613              2084.565132   \n",
       "3             1655.289045          111952.284517              1960.039988   \n",
       "4             1630.656199           79667.267654              1948.503884   \n",
       "\n",
       "   spectral_bandwidth_var  rolloff_mean  ...  mfcc16_var  mfcc17_mean  \\\n",
       "0           117335.771563   3714.560359  ...   39.687145    -3.241280   \n",
       "1            65671.875673   3869.682242  ...   64.748276    -6.055294   \n",
       "2            75124.921716   3997.639160  ...   67.336563    -1.768610   \n",
       "3            82913.639269   3568.300218  ...   47.739452    -3.841155   \n",
       "4            60204.020268   3469.992864  ...   30.336359     0.664582   \n",
       "\n",
       "   mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  mfcc20_mean  \\\n",
       "0   36.488243     0.722209   38.099152    -5.050335   33.618073    -0.243027   \n",
       "1   40.677654     0.159015   51.264091    -2.837699   97.030830     5.784063   \n",
       "2   28.348579     2.378768   45.717648    -1.938424   53.050835     2.517375   \n",
       "3   28.337118     1.218588   34.770935    -3.580352   50.836224     3.630866   \n",
       "4   45.880913     1.689446   51.363583    -3.392489   26.738789     0.536961   \n",
       "\n",
       "   mfcc20_var  label  \n",
       "0   43.771767  blues  \n",
       "1   59.943081  blues  \n",
       "2   33.105122  blues  \n",
       "3   32.023678  blues  \n",
       "4   29.146694  blues  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Some logic derived from reading through the following Kaggle set: https://www.kaggle.com/code/aishwarya2210/let-s-tune-the-music-with-cnn-xgboost/notebook\n",
    "This is for scaling and extracting the features as needed, and converting the labels to numerical values. \n",
    "This will help to create the training and testing sets, then will be fed into the model\n",
    "'''\n",
    "\n",
    "# Label Encoding - encod the categorical classes with numerical integer values for training\n",
    "\n",
    "# Blues - 0\n",
    "# Classical - 1\n",
    "# Country - 2\n",
    "# Disco - 3\n",
    "# Hip-hop - 4 \n",
    "# Jazz - 5  \n",
    "# Metal - 6 \n",
    "# Pop - 7\n",
    "# Reggae - 8\n",
    "# Rock - 9\n",
    "\n",
    "#To convert categorical data into model-understandable numerica data\n",
    "class_list = df.iloc[:, -1]\n",
    "convertor = LabelEncoder()\n",
    "\n",
    "df = df.drop(labels=\"filename\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 9, 9, 9])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the label encoder & return encoded labels\n",
    "y = convertor.fit_transform(class_list)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fit = StandardScaler()\n",
    "X = fit.fit_transform(np.array(df.iloc[:, :-1], dtype = float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6993, 58)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(df.iloc[:,:-1],y,test_size=0.3)\n",
    "x_train.head()\n",
    "# y_train.item(1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[1998, 57], edge_index=[2, 3990006], y=[1998], train_mask=[1998], val_mask=[1998], test_mask=[1998])\n"
     ]
    }
   ],
   "source": [
    "# IGNORING PREVIOUSLY MADE TRAIN/TEST SPLIT\n",
    "\n",
    "# Removing unnecessary variables\n",
    "df = df.drop(labels=\"length\", axis=1)\n",
    "df = df.drop(labels=\"label\", axis=1)\n",
    "\n",
    "# Sample 1% of the data randomly (100th of the total dataset)\n",
    "sample_size = int(df.shape[0] / 5)  # 1% of the total dataset\n",
    "df = df.sample(n=sample_size, random_state=42)  # Randomly sample 1% of the data\n",
    "\n",
    "# Create edge tensor, 1 - Identity Matrix --> tensor\n",
    "adj_matrix = 1 - torch.eye(df.shape[0])\n",
    "edge_index = torch.nonzero(adj_matrix, as_tuple=False).t()\n",
    "\n",
    "# Setting data features to tensor\n",
    "x = torch.tensor(df.values)\n",
    "x = x.to(torch.float32)\n",
    "\n",
    "# NORMALIZE?\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# x = torch.tensor(scaler.fit_transform(df.values), dtype=torch.float32)\n",
    "\n",
    "# Setting y to tensor\n",
    "y = torch.tensor(y[:sample_size], dtype=torch.long)  # Make sure to select only the 1% labels\n",
    "\n",
    "# Create data object\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# Setup test/train/validation split 80/10/10:\n",
    "from sklearn.model_selection import train_test_split\n",
    "# split the data into 80% training and 20% remaining (test + validation)\n",
    "train_indices, remaining_indices = train_test_split(\n",
    "    range(df.shape[0]), test_size=0.2, stratify=y.numpy(), random_state=42\n",
    ")\n",
    "# split the remaining 20% into 50% for validation and 50% for testing\n",
    "val_indices, test_indices = train_test_split(\n",
    "    remaining_indices, test_size=0.5, stratify=y.numpy()[remaining_indices], random_state=42\n",
    ")\n",
    "# initialize masks for each split\n",
    "train_mask = torch.zeros(df.shape[0], dtype=torch.bool)\n",
    "val_mask = torch.zeros(df.shape[0], dtype=torch.bool)\n",
    "test_mask = torch.zeros(df.shape[0], dtype=torch.bool)\n",
    "# set the corresponding entries to True for each mask\n",
    "train_mask[train_indices] = True\n",
    "val_mask[val_indices] = True\n",
    "test_mask[test_indices] = True\n",
    "# assign the masks to the data object\n",
    "data.train_mask = train_mask\n",
    "data.val_mask = val_mask\n",
    "data.test_mask = test_mask\n",
    "\n",
    "# Check dimensions\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([1998, 57])\n",
      "edge_index shape: torch.Size([2, 3990006])\n",
      "y shape: torch.Size([1998])\n",
      "train_mask shape: torch.Size([1998])\n",
      "val_mask shape: torch.Size([1998])\n",
      "test_mask shape: torch.Size([1998])\n"
     ]
    }
   ],
   "source": [
    "print(f\"x shape: {data.x.shape}\")\n",
    "print(f\"edge_index shape: {data.edge_index.shape}\")\n",
    "print(f\"y shape: {data.y.shape}\")\n",
    "print(f\"train_mask shape: {data.train_mask.shape}\")\n",
    "print(f\"val_mask shape: {data.val_mask.shape}\")\n",
    "print(f\"test_mask shape: {data.test_mask.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (layer1): GCNConv(57, 57)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (layer2): GCNConv(57, 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Modified from https://www.geeksforgeeks.org/graph-neural-networks-with-pytorch/\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_rate):\n",
    "        super(GCN, self).__init__()\n",
    "        self.layer1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout_rate)\n",
    "        self.layer2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        #1st Layer\n",
    "        h = self.layer1(x, edge_index)\n",
    "        h = F.relu(h)\n",
    "        #Dropout\n",
    "        h = self.dropout(h)\n",
    "        #2nd Layer\n",
    "        z = self.layer2(h, edge_index)\n",
    "        return z\n",
    "    \n",
    "model_test = GCN(df.shape[1], df.shape[1], 10, 0.5)\n",
    "print(model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the GNN model\n",
    "input_feature_count = df.shape[1]\n",
    "hidden_dim = df.shape[1]  # PICK!\n",
    "num_classes = 10\n",
    "learning_rate = 0.0001\n",
    "weight_decay = 5e-4\n",
    "dropout_rate = 0.5\n",
    "num_epochs = 200\n",
    "\n",
    "model = GCN(input_feature_count, hidden_dim, num_classes, dropout_rate)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "graph_data = data  # Get the graph data\n",
    "\n",
    "# Cross-entropy loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Pre-allocate arrays for loss, training accuracy, and validation accuracy\n",
    "losses = torch.zeros(num_epochs)\n",
    "train_accs = torch.zeros(num_epochs)\n",
    "val_accs = torch.zeros(num_epochs)\n",
    "\n",
    "def train_model():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(graph_data.x, graph_data.edge_index)\n",
    "    loss = criterion(output[graph_data.train_mask], graph_data.y[graph_data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Training accuracy\n",
    "    predictions = output.argmax(dim=1)\n",
    "    correct = (predictions[graph_data.train_mask] == graph_data.y[graph_data.train_mask]).sum()\n",
    "    train_acc = int(correct) / int(graph_data.train_mask.sum())\n",
    "    return loss.item(), train_acc\n",
    "\n",
    "def evaluate_model(mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(graph_data.x, graph_data.edge_index)\n",
    "        predictions = output.argmax(dim=1)\n",
    "        correct = (predictions[mask] == graph_data.y[mask]).sum()\n",
    "        acc = int(correct) / int(mask.sum())\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 200517.9688, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 002, Loss: 202872.8906, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 003, Loss: 185272.2500, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 004, Loss: 182219.8750, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 005, Loss: 182777.7656, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 006, Loss: 176067.1875, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 007, Loss: 175006.4375, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 008, Loss: 184819.5625, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 009, Loss: 172458.4531, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 010, Loss: 171622.1406, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 011, Loss: 179084.2969, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 012, Loss: 163051.2500, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 013, Loss: 169570.9688, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 014, Loss: 164611.8281, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 015, Loss: 168855.2031, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 016, Loss: 158872.5312, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 017, Loss: 161658.6875, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 018, Loss: 163003.3906, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 019, Loss: 142931.1406, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 020, Loss: 150551.5156, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 021, Loss: 157059.7812, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 022, Loss: 158281.4219, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 023, Loss: 142015.5625, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 024, Loss: 139489.3750, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 025, Loss: 149217.6719, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 026, Loss: 139028.0625, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 027, Loss: 134178.7188, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 028, Loss: 132440.7031, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 029, Loss: 135040.8438, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 030, Loss: 126693.8359, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 031, Loss: 139775.9531, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 032, Loss: 113703.7031, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 033, Loss: 130139.6719, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 034, Loss: 120685.4766, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 035, Loss: 114807.8906, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 036, Loss: 114818.3047, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 037, Loss: 119682.6016, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 038, Loss: 102456.3906, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 039, Loss: 106381.5938, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 040, Loss: 115415.9062, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 041, Loss: 107926.8750, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 042, Loss: 103365.1953, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 043, Loss: 103185.6953, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 044, Loss: 99098.5234, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 045, Loss: 108449.2422, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 046, Loss: 100234.8516, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 047, Loss: 99528.2266, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 048, Loss: 96552.2578, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 049, Loss: 98101.5547, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 050, Loss: 87993.1094, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 051, Loss: 92258.8516, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 052, Loss: 85822.0391, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 053, Loss: 80485.0703, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 054, Loss: 82716.7500, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 055, Loss: 82655.2109, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 056, Loss: 87147.0000, Train Acc: 0.0000, Val Acc: 0.0000\n",
      "Epoch: 057, Loss: 76653.4453, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 058, Loss: 82398.6562, Train Acc: 0.0000, Val Acc: 0.5000\n",
      "Epoch: 059, Loss: 77053.2500, Train Acc: 0.0000, Val Acc: 0.5000\n",
      "Epoch: 060, Loss: 78188.1406, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 061, Loss: 75975.6641, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 062, Loss: 75023.2188, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 063, Loss: 73460.6875, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 064, Loss: 76591.8438, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 065, Loss: 74494.5781, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 066, Loss: 73118.8047, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 067, Loss: 72399.3906, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 068, Loss: 71444.7188, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 069, Loss: 70665.9531, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 070, Loss: 70332.6172, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 071, Loss: 70751.5781, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 072, Loss: 69937.4141, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 073, Loss: 66696.6641, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 074, Loss: 67334.8672, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 075, Loss: 67872.8125, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 076, Loss: 66016.9531, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 077, Loss: 68006.7734, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 078, Loss: 63810.7891, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 079, Loss: 61581.3281, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 080, Loss: 63864.4062, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 081, Loss: 63141.2461, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 082, Loss: 65733.0547, Train Acc: 0.0000, Val Acc: 0.5000\n",
      "Epoch: 083, Loss: 62053.7305, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 084, Loss: 60983.9297, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 085, Loss: 62769.1797, Train Acc: 0.0000, Val Acc: 0.5000\n",
      "Epoch: 086, Loss: 59315.1055, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 087, Loss: 62259.4844, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 088, Loss: 57984.0820, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 089, Loss: 58381.0312, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 090, Loss: 56949.6328, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 091, Loss: 57270.4766, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 092, Loss: 57007.5000, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 093, Loss: 53033.8984, Train Acc: 0.0000, Val Acc: 0.5000\n",
      "Epoch: 094, Loss: 53156.7695, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 095, Loss: 52071.2031, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 096, Loss: 54148.4609, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 097, Loss: 51092.6523, Train Acc: 0.0000, Val Acc: 0.5000\n",
      "Epoch: 098, Loss: 54139.4648, Train Acc: 0.0000, Val Acc: 0.5000\n",
      "Epoch: 099, Loss: 56000.0039, Train Acc: 0.0000, Val Acc: 0.5000\n",
      "Epoch: 100, Loss: 55620.3359, Train Acc: 0.0000, Val Acc: 0.5000\n",
      "Epoch: 101, Loss: 44951.6094, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 102, Loss: 50009.3750, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 103, Loss: 45636.3086, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 104, Loss: 49376.8203, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 105, Loss: 48220.8242, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 106, Loss: 42467.0586, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 107, Loss: 50514.2422, Train Acc: 0.0000, Val Acc: 0.5000\n",
      "Epoch: 108, Loss: 45812.0469, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 109, Loss: 43844.5742, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 110, Loss: 47243.6562, Train Acc: 0.0000, Val Acc: 0.5000\n",
      "Epoch: 111, Loss: 40602.0508, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 112, Loss: 42279.2656, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 113, Loss: 38977.1602, Train Acc: 0.0000, Val Acc: 0.5000\n",
      "Epoch: 114, Loss: 42405.3203, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 115, Loss: 42988.6758, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 116, Loss: 40238.6445, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 117, Loss: 38466.0859, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 118, Loss: 39331.3984, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 119, Loss: 36905.9766, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 120, Loss: 46253.3750, Train Acc: 0.0000, Val Acc: 0.5000\n",
      "Epoch: 121, Loss: 31670.9414, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 122, Loss: 37195.3867, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 123, Loss: 33547.6758, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 124, Loss: 35446.7070, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 125, Loss: 38506.3867, Train Acc: 0.0000, Val Acc: 0.5000\n",
      "Epoch: 126, Loss: 37591.4805, Train Acc: 0.0000, Val Acc: 0.5000\n",
      "Epoch: 127, Loss: 33670.0586, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 128, Loss: 30439.4492, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 129, Loss: 31406.3926, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 130, Loss: 29338.3906, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 131, Loss: 29823.3770, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 132, Loss: 28030.3105, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 133, Loss: 31956.1621, Train Acc: 0.0000, Val Acc: 0.5000\n",
      "Epoch: 134, Loss: 26785.3398, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 135, Loss: 27976.9707, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 136, Loss: 25078.6992, Train Acc: 0.5006, Val Acc: 0.5000\n",
      "Epoch: 137, Loss: 24060.0684, Train Acc: 0.5006, Val Acc: 0.5000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 3\u001b[0m     loss_value, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m evaluate_model(graph_data\u001b[38;5;241m.\u001b[39mval_mask)  \u001b[38;5;66;03m# Evaluate on validation set\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Save loss and accuracy for each epoch in pre-allocated arrays\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 29\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m output \u001b[38;5;241m=\u001b[39m model(graph_data\u001b[38;5;241m.\u001b[39mx, graph_data\u001b[38;5;241m.\u001b[39medge_index)\n\u001b[1;32m     28\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output[graph_data\u001b[38;5;241m.\u001b[39mtrain_mask], graph_data\u001b[38;5;241m.\u001b[39my[graph_data\u001b[38;5;241m.\u001b[39mtrain_mask])\n\u001b[0;32m---> 29\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Training accuracy\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    loss_value, train_acc = train_model()\n",
    "    val_acc = evaluate_model(graph_data.val_mask)  # Evaluate on validation set\n",
    "    \n",
    "    # Save loss and accuracy for each epoch in pre-allocated arrays\n",
    "    losses[epoch] = loss_value\n",
    "    train_accs[epoch] = train_acc\n",
    "    val_accs[epoch] = val_acc\n",
    "    \n",
    "    #if (epoch+1) % 10 == 0:\n",
    "    print(f'Epoch: {epoch+1:03d}, Loss: {loss_value:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "# After training, evaluate the model on the test set\n",
    "test_acc = evaluate_model(graph_data.test_mask)  # Evaluate on test set\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
