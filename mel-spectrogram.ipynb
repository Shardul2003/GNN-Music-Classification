{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models, transforms, datasets\n",
    "\n",
    "from time import time\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Code taken from \"https://www.kaggle.com/code/nippani/gtzan-mel-spectrogram-resnet18\"\n",
    "This Kaggle notebook will be used to complete the preprocessing, which is to convert the \n",
    "GTZAN audio tracks to MEL Spectrograms. This cell and the next cell will handle this\n",
    "'''\n",
    "\n",
    "# Parameters\n",
    "seed = 12\n",
    "np.random.seed(seed)\n",
    "\n",
    "path_to_audios = \"Data/genres_original/\"\n",
    "\n",
    "path_imgs = \"./mel_spectrogram_imgs/\"\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "hop_length = 512\n",
    "\n",
    "n_fft = 2048\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "genre_dict = {\"blues\":0,\"classical\":1,\"country\":2,\"disco\":3,\"hiphop\":4,\"jazz\":5,\"metal\":6,\"pop\":7,\"reggae\":8,\"rock\":9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses the audio files directly\n",
    "print(\"Transforming the Audio Files into Mel Spectrograms:\")\n",
    "\n",
    "mel_spectogram_data = {}\n",
    "for genre in genre_dict.keys():\n",
    "    print(\"\\t\",genre)\n",
    "    \n",
    "    mel_spectogram_data[genre] = []\n",
    "\n",
    "    for name in glob.glob(path_to_audios + genre + \"/*\"):\n",
    "        \n",
    "        if(name != \"Data/genres_original/jazz/jazz.00054.wav\"):\n",
    "        \n",
    "            data, sampling_rate = librosa.load(name)\n",
    "\n",
    "            mel_spec = librosa.feature.melspectrogram(y = data.ravel(), sr=sampling_rate, hop_length = hop_length)\n",
    "            mel_spec_db = librosa.amplitude_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "            mel_spectogram_data[genre].append(mel_spec_db)\n",
    "            \n",
    "\n",
    "print(\"Saving the Mel Spectrogram Images:\")\n",
    "            \n",
    "os.mkdir(path_imgs)\n",
    "for genre in genre_dict.keys():\n",
    "    print(\"\\t\",genre)\n",
    "    try:\n",
    "        os.mkdir(path_imgs + genre)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for i in range(len(mel_spectogram_data[genre])):\n",
    "\n",
    "        fig, ax = plt.subplots(1, figsize=(12,8))\n",
    "\n",
    "        img = librosa.display.specshow(mel_spectogram_data[genre][i], sr = sampling_rate, hop_length = hop_length,cmap = 'cool',ax=ax)\n",
    "\n",
    "        fig.savefig(path_imgs + genre + \"/\" + genre + \"_\" + str(i) + \".png\")\n",
    "        \n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses the 3 second features csv that is given\n",
    "\n",
    "print(\"Transforming the Audio Files into Mel Spectrograms:\")\n",
    "\n",
    "mel_spectogram_data2 = {}\n",
    "for genre in genre_dict.keys():\n",
    "    print(\"\\t\", genre)\n",
    "    \n",
    "    mel_spectogram_data2[genre] = []\n",
    "\n",
    "    for name in glob.glob(path_to_audios + genre + \"/*\"):\n",
    "\n",
    "        if(name != \"Data/genres_original/jazz/jazz.00054.wav\"):\n",
    "        \n",
    "            data, sampling_rate = librosa.load(name)\n",
    "\n",
    "            # Extract features\n",
    "            # 1. Mel spectrogram\n",
    "            mel_spec = librosa.feature.melspectrogram(y=data, sr=sampling_rate, n_mels=128, hop_length=512)\n",
    "            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            \n",
    "            # 2. MFCC\n",
    "            mfcc = librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=20)\n",
    "            \n",
    "            # 3. Chroma features\n",
    "            chroma = librosa.feature.chroma_stft(y=data, sr=sampling_rate)\n",
    "            \n",
    "            # 4. Spectral features\n",
    "            spectral_centroids = librosa.feature.spectral_centroid(y=data, sr=sampling_rate)\n",
    "            spectral_rolloff = librosa.feature.spectral_rolloff(y=data, sr=sampling_rate)\n",
    "\n",
    "            song_features = [mel_spec, mel_spec_db, mfcc, chroma, spectral_centroids, spectral_rolloff]\n",
    "            mel_spectogram_data2[genre].append(song_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mel_spectogram_data['jazz'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
